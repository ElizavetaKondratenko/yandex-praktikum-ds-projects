# Классификация комментариев

Код проекта - [ipynb][1]. Описание проекта - [mb][2].

[1]: https://github.com/ElizavetaKondratenko/yandex-praktikum-ds-projects/blob/main/13-%D0%BA%D0%BB%D0%B0%D1%81%D1%81%D0%B8%D1%84%D0%B8%D0%BA%D0%B0%D1%86%D0%B8%D1%8F-%D0%BA%D0%BE%D0%BC%D0%BC%D0%B5%D0%BD%D1%82%D0%B0%D1%80%D0%B8%D0%B5%D0%B2/P13-comments-classifying.ipynb
[2]: https://github.com/ElizavetaKondratenko/yandex-praktikum-ds-projects/edit/main/13-%D0%BA%D0%BB%D0%B0%D1%81%D1%81%D0%B8%D1%84%D0%B8%D0%BA%D0%B0%D1%86%D0%B8%D1%8F-%D0%BA%D0%BE%D0%BC%D0%BC%D0%B5%D0%BD%D1%82%D0%B0%D1%80%D0%B8%D0%B5%D0%B2/README.md

## Основная задача

Для ускорения процесса модерации необходимо подобрать и обучить модель, которая по тексту комментария будет разделять их на токсичные и не токсичные.

## Описание проекта

**Заказчик** - интернет-магазин «Викишоп», который планирует запустить новый сервис. Благодаря данному сервису пользователи смогут редактировать и дополнять описания товаров подобно тому, как это делается в вики-сообществах. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию - модель, которая будет классифицировать комментарии на позитивные и негативные. При этом нужно достичь значение метрики качества F1 не меньше 0.75.

**Исходные данные** - набор данных с разметкой о токсичности правок.

## Сферы деятельности

* Интернет-сервисы
* Интернет-магазины
* Рекламные площадки
* Цифровые агентства & Маркетинг

## Основные инструменты

- **python**
- **pandas**
- **nltk**
- sklearn.feature_extraction.text.**TfidfVectorizer**
- sklearn.model_selection.**RandomizedSearchCV**
- sklearn.ensemble.**RandomForestClassifier**
- sklearn.linear_model.**LogisticRegression**
- catboost.**CatBoostClassifier**

## Выводы

На первом этапе работы мы провели первичную обработку исходных текстов: лемматизировали исходные тексты; удалили ненужные и неинформативные слова, а также почистили тексты от стоп-слов; провели оценку значимости каждого слова в тексте.

После этапа предобработки мы перешли к этапу моделирования. Нами были рассмотрены три модели: логистическая регрессия, случайный лес и CatBoost классификатор. В качестве итоговой была выбрана модель логистической регрессии - именно она имела наилучшее качество на тренировочных данных, а также соответствовала запросу заказчика в f1-score не ниже 0,75.

На тестовых данных итоговая модель показала себя отлично - величина f1 статистики почти не отличается от аналогичного показателя на тренировочных данных, что свидетельствует о минимальном переобучении итоговой модели.
